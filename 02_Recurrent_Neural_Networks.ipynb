{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Recurrent neural networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7EYDXrrzfk_"
      },
      "source": [
        "# **EX01. RNN 實作**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgn3PLBIzzCs"
      },
      "source": [
        "## Step01：載入套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ozwjG2y6WO"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fEJAiSp1hq7"
      },
      "source": [
        "## Step02：測試嵌入層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVhms71D1b4P",
        "outputId": "ee295032-6bec-45be-8c7d-371d49c486b9"
      },
      "source": [
        "# 建立模型\n",
        "seq_model = tf.keras.Sequential()\n",
        "\n",
        "# 模型只含嵌入層(Embedding layer)\n",
        "# 字彙表最大為2000，輸出維度為 64，輸入的字數為 10\n",
        "seq_model.add(layers.Embedding(input_dim=2000, output_dim=64))\n",
        "\n",
        "# 產生亂數資料，32筆資料，每筆 10 個數字\n",
        "input_seq_array = np.random.randint(2000, size=(30, 10))\n",
        "\n",
        "# 指定優化器、損失函數\n",
        "seq_model.compile('rmsprop', 'mse')\n",
        "\n",
        "# 預測\n",
        "output_seq_array = seq_model.predict(input_seq_array)\n",
        "print(output_seq_array.shape)\n",
        "output_array[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 10, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.34097759e-02, -8.97800922e-03, -3.11054289e-04,\n",
              "        -1.24567375e-02,  4.70356606e-02,  1.82210095e-02,\n",
              "        -4.60188463e-03, -3.90012488e-02,  3.33725475e-02,\n",
              "         3.94629277e-02,  3.09496857e-02, -1.34369358e-02,\n",
              "         4.69737314e-02,  3.21288146e-02,  2.39550509e-02,\n",
              "         3.37040685e-02,  9.77888703e-05, -1.40783899e-02,\n",
              "         4.04952839e-03,  3.08198221e-02,  4.30888794e-02,\n",
              "        -6.97095320e-03,  2.81312317e-03,  3.37722786e-02,\n",
              "         4.99996208e-02,  3.06658037e-02,  1.75390579e-02,\n",
              "         1.33836307e-02, -1.53669231e-02, -3.61397974e-02,\n",
              "        -6.74518198e-03, -2.60698795e-02, -1.49730332e-02,\n",
              "        -4.36028242e-02,  1.85554735e-02, -2.28436589e-02,\n",
              "        -1.22305267e-02, -4.55967449e-02,  2.88151167e-02,\n",
              "         2.79277824e-02, -3.38440910e-02,  4.78392579e-02,\n",
              "         4.71436493e-02,  3.24982442e-02,  1.46416165e-02,\n",
              "        -4.43773158e-02, -5.69744036e-03,  5.65637276e-03,\n",
              "         2.86322348e-02,  3.80065925e-02, -2.26779338e-02,\n",
              "        -4.06839363e-02, -4.77945209e-02,  3.79808806e-02,\n",
              "        -1.96002796e-03,  2.53424384e-02, -1.38964504e-03,\n",
              "         4.45702411e-02,  1.46261491e-02,  3.77659686e-02,\n",
              "        -2.22401861e-02, -3.52194794e-02, -3.83908264e-02,\n",
              "         4.09318544e-02],\n",
              "       [-4.27259579e-02,  2.63410844e-02,  3.83641608e-02,\n",
              "        -7.02060387e-03,  5.19413874e-03, -3.08285002e-02,\n",
              "         1.95323341e-02,  4.73489799e-02, -4.43675295e-02,\n",
              "         3.99545170e-02,  4.80634011e-02,  4.98931520e-02,\n",
              "         3.15415859e-03, -1.53051130e-02, -2.60698926e-02,\n",
              "        -4.76058125e-02, -1.11990348e-02, -2.79846080e-02,\n",
              "        -2.43631247e-02,  2.85388492e-02,  1.01507194e-02,\n",
              "        -1.98693760e-02, -4.27279249e-02,  1.34240836e-04,\n",
              "         3.78226116e-03,  4.92099635e-02, -4.37279455e-02,\n",
              "        -4.93485332e-02, -1.70670971e-02,  3.29709314e-02,\n",
              "         3.17968242e-02, -3.03938519e-02,  2.08470710e-02,\n",
              "        -4.26552407e-02, -1.24107376e-02, -4.79468107e-02,\n",
              "        -3.02137490e-02,  8.18973780e-03, -3.36318985e-02,\n",
              "        -3.34690362e-02, -2.26103142e-03, -1.08236074e-03,\n",
              "        -4.03888151e-03, -3.26349624e-02,  3.57102640e-02,\n",
              "        -1.72237381e-02, -5.15832752e-03, -5.02563640e-03,\n",
              "         3.51798050e-02, -1.65690780e-02,  5.14787436e-03,\n",
              "         3.74759920e-02, -2.90570743e-02, -2.91712414e-02,\n",
              "         8.37193802e-03, -3.59251015e-02,  3.46986391e-02,\n",
              "        -5.75119257e-03,  8.37742165e-03, -4.70887870e-04,\n",
              "         4.04799916e-02, -4.18216959e-02, -1.76278129e-02,\n",
              "         4.15495299e-02],\n",
              "       [ 2.47163661e-02,  6.62624836e-04, -4.37631495e-02,\n",
              "         4.55023311e-02, -1.34164914e-02, -1.03351697e-02,\n",
              "        -4.43832539e-02, -1.43525749e-03, -2.58007403e-02,\n",
              "         1.56648196e-02, -2.97607426e-02, -4.58838120e-02,\n",
              "         4.08982970e-02,  4.07239236e-02,  3.43638100e-02,\n",
              "         2.56510265e-02,  1.13693960e-02,  5.61086088e-03,\n",
              "        -2.21986305e-02, -3.47704664e-02,  4.40722741e-02,\n",
              "         3.67130525e-02, -9.54309851e-03,  1.50978565e-04,\n",
              "         1.69322826e-02, -4.65346500e-03,  5.80520555e-03,\n",
              "        -4.28336039e-02, -1.31322369e-02, -6.79595396e-03,\n",
              "        -4.79940549e-02,  9.36895609e-03, -7.66634941e-04,\n",
              "         1.07015595e-02, -4.40012924e-02,  4.67414968e-02,\n",
              "        -3.36719677e-03,  4.14441265e-02, -4.65638563e-03,\n",
              "        -4.86703292e-02,  1.46709345e-02, -3.37697640e-02,\n",
              "         1.73688866e-02,  1.48015879e-02, -4.51737531e-02,\n",
              "         2.06353329e-02, -2.64544617e-02, -1.18159279e-02,\n",
              "         2.55024545e-02,  3.86836417e-02, -1.39723793e-02,\n",
              "        -4.65129502e-02,  1.39275901e-02,  1.39596201e-02,\n",
              "         2.03068592e-02,  3.79142277e-02,  3.97891738e-02,\n",
              "         1.95322894e-02, -4.44118269e-02,  2.05807760e-03,\n",
              "         3.37035917e-02,  1.42128356e-02,  2.68932432e-03,\n",
              "         1.26327612e-02],\n",
              "       [ 4.63154800e-02,  2.51196511e-02,  2.66627185e-02,\n",
              "         1.60984434e-02,  3.25198807e-02,  4.81826551e-02,\n",
              "        -5.08110598e-03,  1.98860280e-02, -6.64780289e-03,\n",
              "        -3.81370783e-02,  2.45728828e-02,  1.62285678e-02,\n",
              "        -4.49366085e-02,  4.40470092e-02, -3.97376046e-02,\n",
              "        -3.72904912e-02,  4.61899377e-02, -2.74890065e-02,\n",
              "        -4.06158082e-02, -6.95108250e-03,  3.05843987e-02,\n",
              "         5.48385084e-04,  4.42347415e-02,  4.50735949e-02,\n",
              "        -4.14711609e-02, -8.22744519e-03,  3.24009731e-03,\n",
              "         2.44172327e-02, -3.30560356e-02,  6.05656952e-03,\n",
              "        -4.25016880e-03,  2.75527276e-02,  1.98224895e-02,\n",
              "        -1.69325620e-04, -3.35147753e-02, -4.79358919e-02,\n",
              "         2.37113237e-03,  4.62681390e-02, -2.39776447e-03,\n",
              "         1.21589787e-02, -1.55891292e-02, -6.36319071e-03,\n",
              "         2.42060460e-02,  3.93055417e-02,  1.29628815e-02,\n",
              "         6.89978525e-03,  1.74477212e-02,  1.52776875e-02,\n",
              "         1.45093091e-02,  3.40751670e-02, -1.70009024e-02,\n",
              "        -3.32295299e-02,  1.72630884e-02,  2.23450698e-02,\n",
              "        -1.40282996e-02, -1.72465555e-02, -3.90174277e-02,\n",
              "         1.72725953e-02, -2.20219493e-02, -4.94754314e-03,\n",
              "        -3.92841808e-02,  3.83575894e-02, -2.44425610e-03,\n",
              "         2.05993913e-02],\n",
              "       [ 2.29623653e-02,  4.36646007e-02,  4.60341237e-02,\n",
              "         2.48247720e-02, -1.69960633e-02, -2.28363518e-02,\n",
              "         1.90561451e-02, -2.71372199e-02, -1.05162635e-02,\n",
              "        -4.04474139e-02, -1.76720992e-02, -4.52002138e-03,\n",
              "        -3.98982652e-02, -5.26599959e-03,  6.16263226e-03,\n",
              "        -4.28786986e-02, -2.16087457e-02, -3.09755448e-02,\n",
              "        -1.87943820e-02,  1.60482414e-02,  3.20133679e-02,\n",
              "        -2.22646724e-02,  4.81118001e-02,  3.99235375e-02,\n",
              "         3.01556848e-02, -4.10717949e-02,  4.14203517e-02,\n",
              "         4.98022698e-02, -1.48379579e-02,  1.11807808e-02,\n",
              "         9.59699228e-03, -1.37649886e-02, -3.26690450e-02,\n",
              "         3.18214409e-02,  3.93907763e-02, -2.59110816e-02,\n",
              "         2.60818750e-04,  2.38004960e-02, -7.74610043e-03,\n",
              "         1.02915615e-03, -3.94859798e-02,  3.48014571e-02,\n",
              "         4.57526185e-02, -4.29575443e-02, -3.94524112e-02,\n",
              "         2.21300833e-02,  3.47771496e-03, -3.20184603e-02,\n",
              "        -4.42245379e-02,  1.00845471e-02,  3.73142101e-02,\n",
              "        -3.59006040e-02, -3.46475020e-02, -4.94227558e-03,\n",
              "         3.55346464e-02,  4.03949954e-02, -2.39740256e-02,\n",
              "         3.59534100e-03, -1.13815442e-02, -4.32394035e-02,\n",
              "         4.97379936e-02, -4.59405780e-02, -1.74650922e-02,\n",
              "         4.14505713e-02],\n",
              "       [-2.61524208e-02, -4.88176607e-02,  4.79755066e-02,\n",
              "         4.53844182e-02, -2.29413155e-02,  4.23200987e-02,\n",
              "         8.04662704e-04,  3.33993770e-02,  1.37773044e-02,\n",
              "         3.72274406e-02,  2.39995606e-02,  2.40659714e-03,\n",
              "        -1.20365135e-02,  4.32479717e-02,  1.76981352e-02,\n",
              "        -3.82504463e-02, -1.23749860e-02, -1.62759200e-02,\n",
              "         2.22130455e-02,  1.21052042e-02, -1.42293200e-02,\n",
              "        -4.08949852e-02,  4.35870625e-02, -1.92690380e-02,\n",
              "        -2.19832547e-02,  4.38296832e-02,  1.19268894e-03,\n",
              "         2.27476396e-02,  2.84892954e-02, -2.09103953e-02,\n",
              "        -2.85622720e-02,  1.57606341e-02,  3.93535830e-02,\n",
              "        -7.34176487e-03, -9.35864449e-03, -8.62453133e-03,\n",
              "         2.29162015e-02, -4.79912758e-03, -4.22765501e-02,\n",
              "        -2.46877801e-02, -4.91738804e-02,  1.05716474e-02,\n",
              "        -3.67590897e-02, -4.31212448e-02,  4.88337018e-02,\n",
              "        -5.58922440e-03,  1.21666789e-02, -3.46326455e-02,\n",
              "        -2.76186708e-02,  1.76491775e-02,  1.03597715e-03,\n",
              "        -2.23199017e-02, -2.67771967e-02,  9.05972719e-03,\n",
              "         1.23245828e-02, -3.14190611e-02, -2.91384812e-02,\n",
              "        -3.47043201e-03, -3.04266103e-02,  3.92743088e-02,\n",
              "         3.30459587e-02, -1.91981439e-02,  4.32489179e-02,\n",
              "         2.20250748e-02],\n",
              "       [ 3.90275009e-02, -3.65620963e-02, -6.99709728e-03,\n",
              "        -4.65292856e-03,  3.94979455e-02, -2.75341999e-02,\n",
              "         2.80989744e-02,  2.97662131e-02,  4.11183499e-02,\n",
              "        -4.57100384e-02, -4.95157018e-02, -4.44418304e-02,\n",
              "        -3.45827453e-02,  3.19058187e-02,  2.30337121e-02,\n",
              "        -2.93571595e-02,  4.40124422e-03,  4.63859551e-02,\n",
              "         4.56276871e-02,  4.68038358e-02, -3.89749184e-02,\n",
              "         3.92540544e-03, -1.01839527e-02, -1.69994459e-02,\n",
              "        -1.77787319e-02, -3.33478339e-02,  3.49891447e-02,\n",
              "        -8.87715816e-03, -4.53861803e-03, -2.09531076e-02,\n",
              "         7.39168376e-04, -4.76337560e-02, -2.24674698e-02,\n",
              "         1.55938156e-02, -1.34677663e-02, -4.89466451e-02,\n",
              "         4.80129458e-02, -2.78286934e-02,  5.92704862e-03,\n",
              "        -3.31293717e-02,  2.00086832e-03,  2.69150846e-02,\n",
              "         2.73017995e-02, -6.59418106e-03, -2.05047373e-02,\n",
              "        -2.95004379e-02,  1.79658569e-02,  1.24729387e-02,\n",
              "         3.08876522e-02,  2.68717147e-02,  2.09751241e-02,\n",
              "        -2.11733580e-02, -2.42048390e-02,  4.34251539e-02,\n",
              "         3.42466123e-02, -1.43884793e-02,  2.18708403e-02,\n",
              "        -4.80243340e-02, -2.41891034e-02, -1.84275992e-02,\n",
              "         2.12189443e-02, -3.62896435e-02,  1.15752704e-02,\n",
              "        -3.55916731e-02],\n",
              "       [ 2.85381414e-02,  3.75302769e-02, -4.06716689e-02,\n",
              "        -5.91038540e-03,  4.25019115e-03,  2.97748707e-02,\n",
              "        -1.41084082e-02, -4.40361165e-02,  1.78003311e-03,\n",
              "        -4.46357504e-02, -2.87680160e-02,  1.32707022e-02,\n",
              "        -4.56723943e-02, -1.67037137e-02, -5.23887575e-04,\n",
              "         5.90323284e-03,  3.46713141e-03, -3.45202573e-02,\n",
              "         3.57860066e-02, -3.56110558e-02,  4.68456745e-03,\n",
              "         1.92367770e-02, -4.92895134e-02,  4.69228886e-02,\n",
              "        -3.95588391e-02, -1.51192546e-02, -1.93650015e-02,\n",
              "        -2.69337744e-03, -2.96074152e-03, -1.37626417e-02,\n",
              "        -3.53632085e-02,  4.57721613e-02, -4.96917851e-02,\n",
              "        -4.16017063e-02,  3.55774164e-03, -4.02386896e-02,\n",
              "         1.52213238e-02,  4.96957339e-02,  4.62681316e-02,\n",
              "        -2.47801896e-02, -1.72743089e-02,  4.30609621e-02,\n",
              "        -1.32366195e-02, -3.46832275e-02, -7.97698647e-03,\n",
              "         4.42301072e-02, -2.04746481e-02,  3.08234431e-02,\n",
              "        -3.51877213e-02, -7.22331926e-03, -1.50198713e-02,\n",
              "        -2.75554415e-02,  8.50493833e-03,  3.98070328e-02,\n",
              "         2.34867595e-02,  2.55304575e-03, -3.81990783e-02,\n",
              "         1.21471062e-02,  1.48626231e-02, -4.49075364e-02,\n",
              "         3.66379656e-02,  9.35747474e-03, -4.97555733e-03,\n",
              "        -2.88832914e-02],\n",
              "       [ 1.48759969e-02, -2.04318762e-03,  3.07929032e-02,\n",
              "         3.73398177e-02, -2.50601526e-02,  2.89760903e-03,\n",
              "         2.29451992e-02,  1.38499178e-02, -1.24410503e-02,\n",
              "        -1.83676705e-02, -1.55705102e-02,  1.81652941e-02,\n",
              "        -1.21439323e-02,  4.45925705e-02, -4.93318923e-02,\n",
              "        -3.85372713e-03, -2.79670358e-02,  4.00271527e-02,\n",
              "         3.37888487e-02,  4.33602594e-02, -4.34291363e-03,\n",
              "        -7.37421215e-05, -4.90489267e-02, -1.59258470e-02,\n",
              "        -7.95725733e-03,  4.09292020e-02, -3.30800898e-02,\n",
              "         1.64557584e-02,  3.24759521e-02,  2.76298262e-02,\n",
              "         1.62683763e-02,  2.68140770e-02, -2.47922894e-02,\n",
              "        -3.26978788e-02,  2.00136788e-02,  3.27485539e-02,\n",
              "        -1.19403601e-02,  3.24278213e-02, -1.43439546e-02,\n",
              "         8.91075283e-03, -3.76388803e-02, -1.29881985e-02,\n",
              "         3.88904549e-02, -3.73849757e-02, -1.72224641e-02,\n",
              "         3.47427465e-02,  3.49888541e-02,  3.34079154e-02,\n",
              "         1.12214684e-02,  9.82906669e-03,  1.66250728e-02,\n",
              "         2.93873288e-02,  2.53132246e-02, -3.50032337e-02,\n",
              "         3.67547199e-03, -2.79206038e-03, -4.25225496e-02,\n",
              "        -1.75380930e-02, -2.62386799e-02, -3.66733782e-02,\n",
              "         4.68635000e-02,  2.06864588e-02,  9.48982313e-03,\n",
              "         4.17780615e-02],\n",
              "       [ 2.93911584e-02,  1.17244832e-02,  2.16501839e-02,\n",
              "        -1.29578933e-02, -3.36593390e-03, -1.83457732e-02,\n",
              "        -4.63183410e-02, -2.43753791e-02, -2.69812346e-03,\n",
              "         1.71842687e-02, -3.00619006e-02, -2.67758500e-02,\n",
              "         3.03509869e-02, -3.01242601e-02,  2.59538405e-02,\n",
              "         4.46749665e-02,  1.07601173e-02,  2.88975947e-02,\n",
              "        -4.36408296e-02, -2.38770843e-02, -2.81268004e-02,\n",
              "         3.87540795e-02,  4.50994410e-02,  1.91731192e-02,\n",
              "        -4.41105627e-02,  1.50685571e-02, -4.86417413e-02,\n",
              "        -1.98338181e-03,  3.31051275e-03, -4.41483036e-02,\n",
              "         4.27313894e-03,  4.56161015e-02,  1.52389444e-02,\n",
              "         2.92361639e-02,  7.84190744e-03, -2.11258773e-02,\n",
              "        -2.43876930e-02, -2.92343386e-02,  4.45617698e-02,\n",
              "        -3.21763642e-02, -3.71301547e-02,  2.14274041e-02,\n",
              "         4.40227427e-02,  2.59015597e-02,  3.92071344e-02,\n",
              "         2.15052851e-02, -2.24858876e-02, -1.94927212e-02,\n",
              "        -1.23272054e-02, -2.83191446e-02,  1.39410160e-02,\n",
              "         3.98486592e-02,  4.60188054e-02, -4.39524427e-02,\n",
              "        -7.94211775e-03,  3.15580107e-02,  4.61348183e-02,\n",
              "         9.53205675e-03,  2.57026590e-02,  3.36047150e-02,\n",
              "        -3.29046249e-02,  3.70146744e-02,  2.91381814e-02,\n",
              "         4.53602150e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z55MmhD429gj"
      },
      "source": [
        "## Step03：轉換真實資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfr57Z5x2H2z",
        "outputId": "a322d175-234a-4605-a85b-3364e02970fb"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 測試資料\n",
        "docs = ['Well done!',\n",
        "        'Great effort',\n",
        "        'Good work',\n",
        "        'Excellent!',\n",
        "        'Good',     \n",
        "        'Weak',\n",
        "        'not good',\n",
        "        'poor work',\n",
        "        'Poor effort!',\n",
        "        'Too bad']\n",
        "\n",
        "# 轉成 one-hot encoding\n",
        "vocab_size = 60\n",
        "maxlen = 4\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "\n",
        "# 轉成固定長度，長度不足則後面補空白\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=maxlen, padding='post')\n",
        "\n",
        "# 模型只有 Embedding\n",
        "seq_model = tf.keras.Sequential()\n",
        "seq_model.add(layers.Embedding(vocab_size, 64, input_length=maxlen))\n",
        "seq_model.compile('rmsprop', 'mse')\n",
        "\n",
        "# 預測\n",
        "output_seq_array = seq_model.predict(padded_docs)\n",
        "output_seq_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 4, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsThSHUa5d_i",
        "outputId": "96b79e8f-02a7-4354-a69c-9d8a53c4e1b6"
      },
      "source": [
        "# one-hot encoding 轉換結果\n",
        "print(encoded_docs[0])\n",
        "\n",
        "# 補空白後的輸入維度\n",
        "print(padded_docs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43, 11]\n",
            "(10, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8FT36uY660r"
      },
      "source": [
        "## Step04：加上完全連接層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8q4PGv76tKl",
        "outputId": "d5c36df2-ead5-4448-9024-b0f7918da2fb"
      },
      "source": [
        "# 定義 10 個語句的正面(1)或負面(0)的情緒\n",
        "labels = np.array([1,0,1,0,1,1,0,0,0,1])\n",
        "\n",
        "vocab_size = 60\n",
        "maxlen = 4\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=maxlen, padding='post')\n",
        "\n",
        "seq_model = tf.keras.Sequential()\n",
        "seq_model.add(layers.Embedding(vocab_size, 8, input_length=maxlen))\n",
        "seq_model.add(layers.Flatten())\n",
        "\n",
        "# 加上完全連接層(Dense)\n",
        "seq_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 指定優化器、損失函數\n",
        "seq_model.compile(optimizer='adam', loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(seq_model.summary())\n",
        "\n",
        "# 模型訓練\n",
        "seq_model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "\n",
        "# 模型評估\n",
        "loss, accuracy = seq_model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_22 (Embedding)     (None, 4, 8)              480       \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 89.999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFZ5MNQb70-H",
        "outputId": "fbebde13-9f45-412c-e180-1f6484904e04"
      },
      "source": [
        "seq_model.predict(padded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5163412 ],\n",
              "       [0.4567597 ],\n",
              "       [0.50977   ],\n",
              "       [0.5032323 ],\n",
              "       [0.5239793 ],\n",
              "       [0.5372017 ],\n",
              "       [0.48231846],\n",
              "       [0.4871411 ],\n",
              "       [0.45932922],\n",
              "       [0.5369796 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ats5nYXz9JoP"
      },
      "source": [
        "## Step05：加上 RNN 神經層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh3GXcZW9BTr",
        "outputId": "0613f4b4-0a7d-4d8d-eacd-7d53038b261c"
      },
      "source": [
        "seq_model = tf.keras.Sequential()\n",
        "seq_model.add(layers.Embedding(vocab_size, 8, input_length=maxlen))\n",
        "\n",
        "# 加上 RNN 神經層，輸出 128 個神經元\n",
        "seq_model.add(layers.SimpleRNN(64))\n",
        "\n",
        "# 加上完全連接層(Dense)\n",
        "seq_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 指定優化器、損失函數\n",
        "seq_model.compile(optimizer='adam', loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(seq_model.summary())\n",
        "# 模型訓練\n",
        "seq_model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "\n",
        "# 模型評估\n",
        "loss, accuracy = seq_model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_23 (Embedding)     (None, 4, 8)              480       \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 64)                4672      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,217\n",
            "Trainable params: 5,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa6JMLdo9ltk",
        "outputId": "2aadd240-d6aa-470e-91c1-d0f044f3e33b"
      },
      "source": [
        "seq_model.predict(padded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.4102613e-01],\n",
              "       [9.7427587e-04],\n",
              "       [9.9647671e-01],\n",
              "       [1.0424721e-02],\n",
              "       [9.9402821e-01],\n",
              "       [9.9698973e-01],\n",
              "       [1.7173968e-01],\n",
              "       [2.0079289e-03],\n",
              "       [6.0889189e-04],\n",
              "       [9.9699819e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWM3uiWcA0gh"
      },
      "source": [
        "# **EX02. 影評資料集情緒分析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXM7acec_Ufl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQzS7AAA_-a"
      },
      "source": [
        "batch_size = 256  # 批量\n",
        "embedding_output_dims = 20  # 嵌入層輸出維度\n",
        "max_sequence_length = 400 # 句子最大字數\n",
        "num_distinct_words = 6000 # 字典\n",
        "number_of_epochs = 10 # 訓練執行週期\n",
        "validation_split = 0.30 # 驗證資料比例\n",
        "verbosity_mode = 1  # 訓練資料訊息顯示程度"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lyRy4CLBQFM",
        "outputId": "348b8ad7-2b7e-4e06-ba7a-36f545a6aa7b"
      },
      "source": [
        "# 載入 IMDB 影評資料集，TensorFlow 已將資料轉為索引值\n",
        "(x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = imdb.load_data(\n",
        "    num_words=num_distinct_words)\n",
        "print(x_train_imdb.shape)\n",
        "print(x_test_imdb.shape)\n",
        "\n",
        "# 長度不足時補 0\n",
        "padded_imdb_inputs = pad_sequences(x_train_imdb, maxlen=max_sequence_length\n",
        "                              , value = 0.0) \n",
        "padded_imdb_inputs_test = pad_sequences(x_test_imdb, maxlen=max_sequence_length\n",
        "                                   , value = 0.0) \n",
        "\n",
        "# 建立模型\n",
        "imdb_model = Sequential()\n",
        "imdb_model.add(Embedding(num_distinct_words, embedding_output_dims, \n",
        "                    input_length=max_sequence_length))\n",
        "imdb_model.add(LSTM(10))\n",
        "imdb_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 指定優化器、損失函數\n",
        "imdb_model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# 模型彙總資訊\n",
        "imdb_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 400, 20)           120000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 10)                1240      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 121,251\n",
            "Trainable params: 121,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1raUZ_N1Bokw",
        "outputId": "2c028bed-a915-4f3c-9f51-90f800a0f8d2"
      },
      "source": [
        "x_test_imdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 1668, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
              "       list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 2, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 2, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "       list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 2, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 2, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 2, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 5421, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 2, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 1239, 5189, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 2, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 2, 2, 3292, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 5900, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 2, 5774, 4, 4770, 5, 95, 271, 23, 6, 2, 2, 2, 5437, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 5664, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 2, 5, 2, 68, 1830, 19, 2, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 2, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 5673, 7, 15, 2, 2, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 2, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
              "       ...,\n",
              "       list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "       list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "       list([1, 6, 52, 2, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 2, 21, 4, 2, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 5698, 3406, 718, 2, 9, 6, 2, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 5205, 382, 4, 91, 2, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2WkFUgkCDm-",
        "outputId": "4e3a4295-98c8-421e-e987-a7da9ed726d0"
      },
      "source": [
        "y_test_imdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuWjRuOWCMmx",
        "outputId": "45eba320-ff97-447d-b864-bb2fd4aea755"
      },
      "source": [
        "# 訓練模型\n",
        "history = imdb_model.fit(padded_imdb_inputs, y_train_imdb, batch_size=batch_size, \n",
        "            epochs=number_of_epochs, verbose=verbosity_mode, \n",
        "            validation_split=validation_split)\n",
        "\n",
        "# 模型評估\n",
        "imdb_test_results = imdb_model.evaluate(padded_imdb_inputs_test, y_test_imdb, verbose=False)\n",
        "print(f'Loss: {imdb_test_results[0]}, Accuracy: {100*test_results[1]}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "69/69 [==============================] - 10s 80ms/step - loss: 0.6796 - accuracy: 0.5971 - val_loss: 0.6206 - val_accuracy: 0.7544\n",
            "Epoch 2/10\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.5545 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.8248\n",
            "Epoch 3/10\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.4362 - accuracy: 0.8514 - val_loss: 0.4261 - val_accuracy: 0.8437\n",
            "Epoch 4/10\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3663 - accuracy: 0.8721 - val_loss: 0.4180 - val_accuracy: 0.8176\n",
            "Epoch 5/10\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3226 - accuracy: 0.8878 - val_loss: 0.3765 - val_accuracy: 0.8509\n",
            "Epoch 6/10\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3141 - accuracy: 0.8819 - val_loss: 0.3629 - val_accuracy: 0.8504\n",
            "Epoch 7/10\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.2821 - accuracy: 0.8999 - val_loss: 0.3669 - val_accuracy: 0.8528\n",
            "Epoch 8/10\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.2453 - accuracy: 0.9154 - val_loss: 0.3617 - val_accuracy: 0.8560\n",
            "Epoch 9/10\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.2309 - accuracy: 0.9218 - val_loss: 0.3716 - val_accuracy: 0.8512\n",
            "Epoch 10/10\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2164 - accuracy: 0.9296 - val_loss: 0.3712 - val_accuracy: 0.8521\n",
            "Loss: 0.3737878203392029, Accuracy: 85.11199951171875%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLh_Ged-Chiu"
      },
      "source": [
        "# 模型存檔\n",
        "imdb_model.save('LSTM_IMDB.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv6dUZmNDMwd",
        "outputId": "4987170f-7b7d-45eb-cbb4-64f5f16fe85b"
      },
      "source": [
        "# 取得字詞與索引的對照表字典\n",
        "imdb_dict = imdb.get_word_index()\n",
        "list(imdb_dict.keys())[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fawn',\n",
              " 'tsukino',\n",
              " 'nunnery',\n",
              " 'sonja',\n",
              " 'vani',\n",
              " 'woods',\n",
              " 'spiders',\n",
              " 'hanging',\n",
              " 'woody',\n",
              " 'trawling',\n",
              " \"hold's\",\n",
              " 'comically',\n",
              " 'localized',\n",
              " 'disobeying',\n",
              " \"'royale\",\n",
              " \"harpo's\",\n",
              " 'canet',\n",
              " 'aileen',\n",
              " 'acurately',\n",
              " \"diplomat's\"]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qEuDPSUDfxx"
      },
      "source": [
        "# 反轉字典，變成索引與字詞的對照表\n",
        "imdb_dict_reversed = {}\n",
        "for k, v in imdb_dict.items():\n",
        "    imdb_dict_reversed[v] = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlCD-VfFDlvQ",
        "outputId": "e639a470-9c23-499c-9eb5-a1807f800eff"
      },
      "source": [
        "imdb_text = []\n",
        "for i, line in enumerate(padded_imdb_inputs_test[:8]):\n",
        "    imdb_text.append('')\n",
        "    for j, word in enumerate(line):\n",
        "        if word != 0:\n",
        "            imdb_text[i] += imdb_dict_reversed[word]+' '\n",
        "\n",
        "print('\\n\\n\\n'.join(imdb_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the wonder own as by is sequence i i and and to of hollywood br of down shouting getting boring of ever it sadly sadly sadly i i was then does don't close and after one carry as by are be and all family turn in does as three part in another some to be probably with world and her an have and beginning own as is sequence \n",
            "\n",
            "\n",
            "the as you world's is quite br mankind most that quest are chase to being quickly of little it time hell to plot br of something long put are of every place this and and of and storytelling being nasty not of you warren in is failed club i i of films pay so sequences and film okay uses to received and if time done for room sugar viewer as cartoon of gives to forgettable br be because many these of reflection sugar contained gives it wreck scene to more was two when had find as you another it of themselves probably who and storytelling if itself by br about 1950's films not would effects that her box to miike for if hero close seek end is very together movie of and got say kong sugar fred close bore there is playing lot of and pan place trilogy of lacks br of their time much this men as on it is telling program br silliness okay and to frustration at corner and she of sequences to political clearly in of drugs keep guy i i was throwing room sugar as it by br be plot many for occasionally film and boyfriend difficult kid as you it failed not if gerard to if woman in and is police fi spooky or of self what have pretty in can so suit you good 2 which why super as it main of my i i  if time screenplay in same this remember assured have action one in realistic that better of lessons \n",
            "\n",
            "\n",
            "and except to de and br of you available but hours animals showing br of and than dead white splatter waiting film and to and this documentary in 3 and of accents and br of ann i i comes 9 it place this is and of and and know of mode he bonus film were central to one oh is excellent and in can when from well people in characters' chief from leaving in and and but is easily of and he and speak this as today paul that against one will actual in could her plot and and few grade marc go and but be lot it oliver movie is and picture and feel this of and like different just clichéd girl at finds is and no and glory any is children's just moment like and any of and leaving for as it even cliche to purchased is money easily and and glory any is and i i and film as and set actually easily like outdated sequel any of and ryan made film is and br and constant and of 90s letting deep in act made of road in of and movie and rural vhs of share in reaching fact of and and spinal of 90s to them book are is and and and mode they funniest is white courage and vegas wooden br of gender and unfortunately of 1968 no of years hokey and true up and and but 3 all ordinary be and to and were deserve film and and of creative br comes their kung who is assuming and out new all it incomprehensible it episode much that's including i i cartoon of my certain no as and over you with way to cartoon of enough for that with way who is finished and they of rukh br for and and stunts black that story at actual in can as movie is and has though songs and action it's action his one me and and this second no all way and not lee and be moves br figure of you boss movie is and 9 br propaganda and and after at of smoke splendid snow saturday it's results this of load it's think class br think cop for games make southern things to it and who and if is boyfriend you which is tony by this make and too not make above it even background \n",
            "\n",
            "\n",
            "the was stick did as roles br on take as my was although except torture in perspective of goes he's was big people for was into out improved has that as with boy weapon of seems for ago film of performances production he time relationship not of grade great he jean misses was rather is boat say around thought to was well constructed except much take was story his people star of blood of over fun end this as on other of killer this as on it and film about history in of come br and was saying was three her length has about to about unusual most was story one let's town of genre when is seriously would with long only king's to future deep i'm dvd have can about people friends of here other it especially fan often somewhere br doesn't characters for he means her seemed states by well potential can when it never means movie so night bad he and daughter film of unusual are of goes her them such of number big bad one left bloody \n",
            "\n",
            "\n",
            "the just good because great cold watching is minute each shirley completely to was several as b i i as b gave compared rest not includes we if main that movie sometimes movie have sex man endearing of feet he played to and from into pot have and man second hand in and watching his offering as b it other and to it taste bit i i in perfect as slowly truth was one in perfect only deliver sleazy has thrown not wonder classic as b satisfied at main that i i their among among without didn't later if for very and didn't clearly and didn't forget didn't \n",
            "\n",
            "\n",
            "the watching boy couch as on interesting never aunt an like did as on real and badly to and of purchased but that eyed average one in exploitation that them final realistic taxi but shock was does dvd to shock this as on off is very together to was fantastic scares some such badly victims maybe as on are year it's are unknown this factor assured they there's was fantastic life think taxi as it is alexander very on to real at life who an of production this of actually believes then also in can that to was two from real that real they there's at maybe those are of journey as on thing met is 8 and that fairly of now 10 watching any years as on into at are year \n",
            "\n",
            "\n",
            "this of and this par of demise may of ended to were beneath it pitiful film and to of and and br of wife's and were vivid film and i i and engaging of medical br what's so without to fifties that cast not or is compared money blown in and thief of anna br is and and of jack own want as hard comes cases encourage and of 5 br of here as medical it short this performance someone they and other no of and and it and show of able be and and or of and that with while composer for of broken short in and to surely of and and sacrifice as paul earned of rolled in of miserable br of and cop i i of its equal paul this of you to came this an br you guess it of and letting of brazil and br of letting he waiting film thrillers br cares and to earlier stop it point 1971 to his poster worst of century audiences br of surprises br is again into performance this of emma br of self victim i i of and female br and and to jumps and of letting he porno and film both derek hysterical or is gross they of try br of letting of 'the br of paul it meaningless and may of and constantly to is again and like and she plastic in and any in known is wants she br is annoyed school and this fact watch never instantly who is and massive it of actresses and br of werewolf and this and this and to lines is schools disappointment br of fact br of and and i i of home br is got killer lame in is imdb and and things of letting this is paul for there will and who mirror this obsessed and who dancers and this 2004 to ready and this of and as paul it running shoes or co repeated marriage burned some when away with see is strange father share i i and it is you for of brooklyn we're and that but though example recognize to that but of and that and br leading to and film of simplistic and br of and and and make suspense step there will are you al like one brenda to see compared movements are health grief this behaviour drama 1995 gore \n",
            "\n",
            "\n",
            "the of and animation and male it and in and explanation feat male take no and and and risk this kill in exploitation is vhs fred in of peak be male it mentally who and male watch is popular catch know and it and or kill is and mentality for and male isn't and male her for would well thousands about and heat as it and to of universe form this did her people and to and of hollywood br of you furthermore who film reading to they of here and male lines enemy not like it of help i i of male their it of time buy treatment for it short in classic to pay is their may comedic make is getting using more he either watched yourself g an br really he judge do 7 to commercial annie make out so told rest you and there movies plot jack this having sidekick to childhood any this so family stopped stunning make his makes your not make present in at and to explanation one bit get still been as \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RexLb0lfD0oY",
        "outputId": "d1d710c1-9275-485b-8ede-c50a83656382"
      },
      "source": [
        "imdb_dict_reversed[588]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'please'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUk1xKegECpi",
        "outputId": "83d48bdf-f3a0-4dcd-a110-1574ee06b73b"
      },
      "source": [
        "imdb_dict['please']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "588"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xjn8xE8Nnwt"
      },
      "source": [
        "# **EX03. 情緒分析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_76jClbEU2B"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Activation, Dense, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufdUjebvVXTv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}